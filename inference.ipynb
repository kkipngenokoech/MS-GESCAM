{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5abcf1",
   "metadata": {},
   "source": [
    "# GESCAM Inference Demo\n",
    "\n",
    "This notebook demonstrates how to use a trained GESCAM model for gaze prediction in classroom settings.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8591c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae658c4",
   "metadata": {},
   "source": [
    "Let's download the inference script if not already available:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1646dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the inference script exists, if not create it\n",
    "inference_script_path = 'gescam_inference.py'\n",
    "\n",
    "if not os.path.exists(inference_script_path):\n",
    "    # Download from your repository or copy the code here\n",
    "    print(\"Creating inference script...\")\n",
    "    with open(inference_script_path, 'w') as f:\n",
    "        f.write(\"\"\"\n",
    "# Paste the entire content of the gescam_inference.py script here\n",
    "\"\"\")\n",
    "    print(\"Inference script created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965a4ea",
   "metadata": {},
   "source": [
    "Now import the GazeInference class from the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the current directory to path if needed\n",
    "if '.' not in sys.path:\n",
    "    sys.path.append('.')\n",
    "\n",
    "# Import the GazeInference class\n",
    "from gescam_inference import GazeInference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446aeab8",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "Load your trained model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e93a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your model\n",
    "model_path = 'path/to/your/model.pt'  # Update this with your model path\n",
    "\n",
    "# Initialize inference module\n",
    "inference = GazeInference(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf088b5",
   "metadata": {},
   "source": [
    "## Process a Single Image\n",
    "\n",
    "Let's test the model with a single image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to test image (update with your image)\n",
    "test_image_path = 'path/to/your/test/image.jpg'\n",
    "\n",
    "# Display the image\n",
    "img = Image.open(test_image_path)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(np.array(img))\n",
    "plt.title(\"Test Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd91d3",
   "metadata": {},
   "source": [
    "Now let's detect faces in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Detect faces\n",
    "img_array = np.array(img)\n",
    "gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "# Convert to normalized coordinates\n",
    "height, width = img_array.shape[:2]\n",
    "head_boxes = []\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    # Convert to normalized coordinates\n",
    "    x1, y1 = x / width, y / height\n",
    "    x2, y2 = (x + w) / width, (y + h) / height\n",
    "    \n",
    "    head_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "# Display image with face detection boxes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img_array)\n",
    "for head_bbox in head_boxes:\n",
    "    x1, y1, x2, y2 = head_bbox\n",
    "    # Convert to pixel coordinates for plotting\n",
    "    x1, x2 = x1 * width, x2 * width\n",
    "    y1, y2 = y1 * height, y2 * height\n",
    "    plt.gca().add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                               fill=False, edgecolor='green', linewidth=2))\n",
    "plt.title(f\"Detected {len(head_boxes)} faces\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# If no faces detected, use a default box\n",
    "if not head_boxes:\n",
    "    print(\"No faces detected, using default box\")\n",
    "    head_boxes = [[0.4, 0.4, 0.6, 0.6]]  # Default box in the center\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9627a",
   "metadata": {},
   "source": [
    "Now let's predict the gaze for each detected face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb470bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, head_bbox in enumerate(head_boxes):\n",
    "    # Predict gaze\n",
    "    gaze_heatmap, in_frame_prob, visualization = inference.predict(\n",
    "        img, head_bbox\n",
    "    )\n",
    "    \n",
    "    # Display the visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(visualization)\n",
    "    plt.title(f\"Face {i+1}: Gaze Prediction (In-frame probability: {in_frame_prob:.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # You can also access the raw heatmap separately\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(gaze_heatmap, cmap='jet')\n",
    "    plt.title(f\"Raw Gaze Heatmap for Face {i+1}\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999b001",
   "metadata": {},
   "source": [
    "## Process a Video\n",
    "\n",
    "Let's also try processing a video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82255565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to test video (update with your video)\n",
    "test_video_path = 'path/to/your/test/video.mp4'\n",
    "\n",
    "# Output video path\n",
    "output_video_path = 'gaze_prediction_output.mp4'\n",
    "\n",
    "# Create a face tracker function\n",
    "def face_tracker(frame_cascade):\n",
    "    def tracker(frame):\n",
    "        # Convert to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = frame_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        \n",
    "        # Convert to normalized coordinates\n",
    "        height, width = frame.shape[:2]\n",
    "        head_boxes = []\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            # Convert to normalized coordinates\n",
    "            x1, y1 = x / width, y / height\n",
    "            x2, y2 = (x + w) / width, (y + h) / height\n",
    "            \n",
    "            head_boxes.append([x1, y1, x2, y2])\n",
    "        \n",
    "        # If no faces detected, use a default box\n",
    "        if not head_boxes:\n",
    "            head_boxes = [[0.4, 0.4, 0.6, 0.6]]  # Default box\n",
    "            \n",
    "        return head_boxes\n",
    "    \n",
    "    return tracker\n",
    "\n",
    "# Process video\n",
    "inference.process_video(\n",
    "    test_video_path,\n",
    "    output_path=output_video_path,\n",
    "    head_tracker=face_tracker(face_cascade),\n",
    "    detector=None,  # No object detector for simplicity\n",
    "    sample_rate=5  # Process every 5th frame for speed\n",
    ")\n",
    "\n",
    "# Display a link to download the video\n",
    "from IPython.display import HTML\n",
    "if os.path.exists(output_video_path):\n",
    "    print(f\"Video saved to: {output_video_path}\")\n",
    "    # Display video if in a notebook\n",
    "    try:\n",
    "        from IPython.display import Video\n",
    "        display(Video(output_video_path, width=640))\n",
    "    except ImportError:\n",
    "        print(\"IPython.display.Video not available. Cannot display the video inline.\")\n",
    "else:\n",
    "    print(\"Error: Output video was not created.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb0c99",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to use the GESCAM model for gaze prediction. The model can be used with both images and videos, and can be integrated with face detection for automatic head tracking.\n",
    "\n",
    "For best results, consider:\n",
    "1. Using a specialized head detector instead of a face detector\n",
    "2. Integrating an object detector for classroom objects\n",
    "3. Fine-tuning the model on your specific classroom environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21bdc12",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
